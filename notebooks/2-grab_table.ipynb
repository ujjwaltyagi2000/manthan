{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1 \n",
    "\n",
    "states_dict = {\n",
    "    1: 'Andaman and Nicobar Islands',\n",
    "    2: 'Andhra Pradesh',\n",
    "    3: 'Arunachal Pradesh',\n",
    "    4: 'Assam',\n",
    "    5: 'Bihar',\n",
    "    6: 'Chandigarh',\n",
    "    7: 'Chhattisgarh',\n",
    "    8: 'Dadra and Nagar Haveli and Daman and Diu',\n",
    "    9: 'Delhi',\n",
    "    10: 'Goa',\n",
    "    11: 'Gujarat',\n",
    "    12: 'Haryana',\n",
    "    13: 'Himachal Pradesh',\n",
    "    14: 'Jammu and Kashmir',\n",
    "    15: 'Jharkhand',\n",
    "    16: 'Karnataka',\n",
    "    17: 'Kerala',\n",
    "    18: 'Ladakh',\n",
    "    19: 'Lakshadweep',\n",
    "    20: 'Madhya Pradesh',\n",
    "    21: 'Maharashtra',\n",
    "    22: 'Manipur',\n",
    "    23: 'Meghalaya',\n",
    "    24: 'Mizoram',\n",
    "    25: 'Nagaland',\n",
    "    26: 'Odisha',\n",
    "    27: 'Puducherry',\n",
    "    28: 'Punjab',\n",
    "    29: 'Rajasthan',\n",
    "    30: 'Sikkim',\n",
    "    31: 'Tamil Nadu',\n",
    "    32: 'Telangana',\n",
    "    33: 'Tripura',\n",
    "    34: 'Uttar Pradesh',\n",
    "    35: 'Uttarakhand',\n",
    "    36: 'West Bengal'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024 Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "for state in range(1, 37):\n",
    "    page = 1\n",
    "    while True:\n",
    "        url = f\"https://myneta.info/LokSabha2024/index.php?action=show_constituencies&state_id={state}&page={page}\"\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until the table is loaded\n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'w3-responsive')))\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        table_elements = driver.find_elements(By.CLASS_NAME, 'w3-responsive')\n",
    "\n",
    "        for table in table_elements:\n",
    "            html_content = table.get_attribute(\"outerHTML\")\n",
    "            \n",
    "            # Use BeautifulSoup to parse the HTML and remove <script> tags\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()  # Remove the script and style tags\n",
    "            \n",
    "            cleaned_html = soup.prettify()\n",
    "\n",
    "            with open(f\"../data/html/candidate-background-2024/{states_dict[state]}_{page}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(cleaned_html)\n",
    "\n",
    "        # Check if there is a next page\n",
    "        try:\n",
    "            pagination_div = driver.find_element(By.XPATH, \"//div[center]/center\")\n",
    "            pagination_soup = BeautifulSoup(pagination_div.get_attribute(\"outerHTML\"), 'html.parser')\n",
    "            pages_text = pagination_soup.find(\"small\").text.strip()\n",
    "            total_pages = int(pages_text.split()[-2])\n",
    "\n",
    "            if page < total_pages:\n",
    "                page += 1\n",
    "            else:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019 Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State dictionary for the 2019 election (with their unique IDs)\n",
    "states_dict = {\n",
    "    34: 'Andhra Pradesh',\n",
    "    35: 'Arunachal Pradesh',\n",
    "    36: 'Assam',\n",
    "    37: 'Bihar',\n",
    "    38: 'Goa',\n",
    "    39: 'Gujarat',\n",
    "    40: 'Haryana',\n",
    "    41: 'Himachal Pradesh',\n",
    "    42: 'Jammu and Kashmir',\n",
    "    43: 'Karnataka',\n",
    "    44: 'Kerala',\n",
    "    45: 'Madhya Pradesh',\n",
    "    46: 'Maharashtra',\n",
    "    47: 'Manipur',\n",
    "    48: 'Meghalaya',\n",
    "    49: 'Mizoram',\n",
    "    50: 'Nagaland',\n",
    "    51: 'Odisha',\n",
    "    52: 'Punjab',\n",
    "    53: 'Rajasthan',\n",
    "    54: 'Sikkim',\n",
    "    55: 'Tamil Nadu',\n",
    "    56: 'Telangana',\n",
    "    57: 'Tripura',\n",
    "    58: 'Uttar Pradesh',\n",
    "    59: 'Chhattisgarh',  # Adjusted index\n",
    "    60: 'Jharkhand',      # Adjusted index\n",
    "    61: 'Uttarakhand'     # Adjusted index\n",
    "}\n",
    "\n",
    "# Union territory dictionary for the 2019 election (with their unique IDs)\n",
    "union_territories_dict = {\n",
    "    62: 'Andaman and Nicobar Islands',\n",
    "    63: 'Chandigarh',\n",
    "    64: 'Dadra and Nagar Haveli',\n",
    "    65: 'Daman and Diu',\n",
    "    66: 'Lakshadweep',\n",
    "    67: 'National Capital of Delhi',\n",
    "    68: 'Puducherry'\n",
    "}\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Function to fetch data for a given state or union territory ID\n",
    "def fetch_data_for_id(state_id, state_name):\n",
    "    page = 1\n",
    "    while True:\n",
    "        url = f\"https://myneta.info/LokSabha2019/index.php?action=show_constituencies&state_id={state_id}&page={page}\"\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until the table is loaded\n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'w3-responsive')))\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        table_elements = driver.find_elements(By.CLASS_NAME, 'w3-responsive')\n",
    "\n",
    "        for table in table_elements:\n",
    "            html_content = table.get_attribute(\"outerHTML\")\n",
    "            \n",
    "            # Use BeautifulSoup to parse the HTML and remove <script> tags\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()  # Remove the script and style tags\n",
    "            \n",
    "            cleaned_html = soup.prettify()\n",
    "\n",
    "            # Save HTML content to file\n",
    "            with open(f\"../data/html/candidate-background-2019/{state_name}_{page}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(cleaned_html)\n",
    "\n",
    "        # Check if there is a next page\n",
    "        try:\n",
    "            pagination_div = driver.find_element(By.XPATH, \"//div[center]/center\")\n",
    "            pagination_soup = BeautifulSoup(pagination_div.get_attribute(\"outerHTML\"), 'html.parser')\n",
    "            pages_text = pagination_soup.find(\"small\").text.strip()\n",
    "            total_pages = int(pages_text.split()[-2])\n",
    "\n",
    "            if page < total_pages:\n",
    "                page += 1\n",
    "            else:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "\n",
    "# Fetch data for states\n",
    "for state_id, state_name in states_dict.items():\n",
    "    fetch_data_for_id(state_id, state_name)\n",
    "\n",
    "# Fetch data for union territories\n",
    "for ut_id, ut_name in union_territories_dict.items():\n",
    "    fetch_data_for_id(ut_id, ut_name)\n",
    "\n",
    "# Close the driver after fetching all data\n",
    "driver.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manthan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
